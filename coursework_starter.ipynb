{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOqtixLa1y-b"
   },
   "source": [
    "The following example notebook implements standard diffusion\n",
    "with a simple CNN model to generate realistic MNIST digits.\n",
    "\n",
    "This is a modified implementation of `minDiffusion`\n",
    "which implements [DDPM](https://arxiv.org/abs/2006.11239)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this example notebook,\n",
    "install requirements as in `requirements.txt` (for example, `pip install -r requirements.txt`).\n",
    "You may also wish to follow system-dependent PyTorch instructions\n",
    "[here](https://pytorch.org/) to install accelerated\n",
    "versions of PyTorch, but note they are not needed\n",
    "(I am testing this on my laptop).\n",
    "\n",
    "If you do use accelerated hardware, make sure that your code\n",
    "is still compatible with CPU-only installs.\n",
    "\n",
    "First, let's create a folder to store example images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gaJ7P2ft2G6j",
    "outputId": "7ce57688-755a-431b-c73d-2e32301824ea"
   },
   "outputs": [],
   "source": [
    "!mkdir -p contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "50FGtZsk1y-b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\appfiles\\anaconda\\envs\\cw_aml\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import Accelerator\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function creates a DDPM training schedule for use when evaluating\n",
    "and training the diffusion model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```noise schedular```\n",
    "forward process: build the inputs for our model, which are more and more noisy images. Instead of doing sequentially, we can use the closed form provided in the paprts to calculate the image for any of the timesteps individually (sum of gaussians is also gaussian)\n",
    "\n",
    "zt|x0 = sqrt(alphat)x0 + sqrt(1-aplphat)sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MMQ1-BSc1y-c"
   },
   "outputs": [],
   "source": [
    "def ddpm_schedules(beta1: float, beta2: float, T: int) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Returns pre-computed schedules for DDPM sampling with a linear noise schedule.\"\"\"\n",
    "    assert beta1 < beta2 < 1.0, \"beta1 and beta2 must be in (0, 1)\"\n",
    "\n",
    "    beta_t = (beta2 - beta1) * torch.arange(0, T + 1, dtype=torch.float32) / T + beta1\n",
    "    alpha_t = torch.exp(torch.cumsum(torch.log(1 - beta_t), dim=0))  # Cumprod in log-space (better precision)\n",
    "\n",
    "    return {\"beta_t\": beta_t, \"alpha_t\": alpha_t}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a simple 2D convolutional neural network. This network\n",
    "is essentially going to try to estimate the diffusion process --- we\n",
    "can then use this network to generate realistic images.\n",
    "\n",
    "First, we create a single CNN block which we will stack to create the\n",
    "full network. We use `LayerNorm` for stable training and no batch dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "d16i_bcV1y-d"
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        *,\n",
    "        expected_shape,\n",
    "        act=nn.GELU,\n",
    "        kernel_size=7,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
    "            nn.LayerNorm((out_channels, *expected_shape)), \n",
    "            act()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the full CNN model, which is a stack of these blocks\n",
    "according to the `n_hidden` tuple, which specifies the number of\n",
    "channels at each hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```CNN```\n",
    "not unet here (no downsampling) the image shape remains consistent\n",
    "\n",
    "The imput is a noisy image, the output is the noise in the image (backward process)\n",
    "\n",
    "time embedding is trainable via a fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZSvzdt1f1y-d"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        expected_shape=(28, 28),\n",
    "        n_hidden=(64, 128, 64),\n",
    "        kernel_size=7,\n",
    "        last_kernel_size=3,\n",
    "        time_embeddings=16, \n",
    "        act=nn.GELU,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        last = in_channels\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        for hidden in n_hidden:\n",
    "            self.blocks.append(\n",
    "                CNNBlock(\n",
    "                    last,\n",
    "                    hidden,\n",
    "                    expected_shape=expected_shape,\n",
    "                    kernel_size=kernel_size,\n",
    "                    act=act,\n",
    "                )\n",
    "            )\n",
    "            last = hidden\n",
    "\n",
    "        # The final layer, we use a regular Conv2d to get the\n",
    "        # correct scale and shape (and avoid applying the activation)\n",
    "        self.blocks.append(\n",
    "            nn.Conv2d(\n",
    "                last,\n",
    "                in_channels,\n",
    "                last_kernel_size,\n",
    "                padding=last_kernel_size // 2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ## This part is literally just to put the single scalar \"t\" into the CNN\n",
    "        ## in a nice, high-dimensional way:\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(time_embeddings * 2, 128), act(),\n",
    "            nn.Linear(128, 128), act(),\n",
    "            nn.Linear(128, 128), act(),\n",
    "            nn.Linear(128, n_hidden[0]),\n",
    "        )\n",
    "        frequencies = torch.tensor(\n",
    "            [0] + [2 * np.pi * 1.5**i for i in range(time_embeddings - 1)]\n",
    "        ) # 1.5 is a hyperparameter means that the frequency of the time encoding increases by 1.5x each time\n",
    "        self.register_buffer(\"frequencies\", frequencies)\n",
    "\n",
    "    def time_encoding(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        phases = torch.concat(\n",
    "            (\n",
    "                torch.sin(t[:, None] * self.frequencies[None, :]), # has shape (batch, time_embeddings)\n",
    "                torch.cos(t[:, None] * self.frequencies[None, :]) - 1, # has shape (batch, time_embeddings)\n",
    "            ),\n",
    "            dim=1,\n",
    "        ) # has shape (batch, time_embeddings * 2)\n",
    "\n",
    "        return self.time_embed(phases)[:, :, None, None] # has shape (batch, n_hidden[0], 1, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        # Shapes of input:\n",
    "        #    x: (batch, chan, height, width)\n",
    "        #    t: (batch,)\n",
    "\n",
    "        embed = self.blocks[0](x)\n",
    "        # ^ (batch, n_hidden[0], height, width)\n",
    "\n",
    "        # Add information about time along the diffusion process\n",
    "        #  (Providing this information by superimposing in latent space)\n",
    "        embed += self.time_encoding(t) \n",
    "        #         ^ (batch, n_hidden[0], 1, 1) - thus, broadcasting\n",
    "        #           to the entire spatial domain\n",
    "\n",
    "        for block in self.blocks[1:]:\n",
    "            embed = block(embed)\n",
    "\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the actual diffusion model, which specifies the training\n",
    "schedule, takes an arbitrary model for estimating the\n",
    "diffusion process (such as the CNN above),\n",
    "and computes the corresponding loss (as well as generating samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pCZe8Q651y-d"
   },
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        gt,\n",
    "        betas: Tuple[float, float],\n",
    "        n_T: int,\n",
    "        criterion: nn.Module = nn.MSELoss(),\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.gt = gt \n",
    "\n",
    "        noise_schedule = ddpm_schedules(betas[0], betas[1], n_T)\n",
    "\n",
    "        # `register_buffer` will track these tensors for device placement, but\n",
    "        # not store them as model parameters. This is useful for constants.\n",
    "        self.register_buffer(\"beta_t\", noise_schedule[\"beta_t\"])\n",
    "        self.beta_t  # Exists! Set by register_buffer\n",
    "        self.register_buffer(\"alpha_t\", noise_schedule[\"alpha_t\"])\n",
    "        self.alpha_t\n",
    "\n",
    "        self.n_T = n_T\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 18.1 in Prince\"\"\"\n",
    "\n",
    "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
    "        eps = torch.randn_like(x)  # eps ~ N(0, 1)\n",
    "        alpha_t = self.alpha_t[t, None, None, None]  # Get right shape for broadcasting\n",
    "\n",
    "        z_t = torch.sqrt(alpha_t) * x + torch.sqrt(1 - alpha_t) * eps\n",
    "        # This is the z_t, which is sqrt(alphabar) x_0 + sqrt(1-alphabar) * eps\n",
    "        # We should predict the \"error term\" from this z_t. Loss is what we return.\n",
    "\n",
    "        return self.criterion(eps, self.gt(z_t, t / self.n_T))\n",
    "\n",
    "    def sample(self, n_sample: int, size, device) -> torch.Tensor:\n",
    "        \"\"\"Algorithm 18.2 in Prince\"\"\"\n",
    "\n",
    "        _one = torch.ones(n_sample, device=device)\n",
    "        z_t = torch.randn(n_sample, *size, device=device)\n",
    "        for i in range(self.n_T, 0, -1):\n",
    "            alpha_t = self.alpha_t[i]\n",
    "            beta_t = self.beta_t[i]\n",
    "\n",
    "            # First line of loop:\n",
    "            z_t -= (beta_t / torch.sqrt(1 - alpha_t)) * self.gt(z_t, (i/self.n_T) * _one)\n",
    "            z_t /= torch.sqrt(1 - beta_t)\n",
    "\n",
    "            if i > 1:\n",
    "                # Last line of loop:\n",
    "                z_t += torch.sqrt(beta_t) * torch.randn_like(z_t)\n",
    "            # (We don't add noise at the final step - i.e., the last line of the algorithm)\n",
    "\n",
    "        return z_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run this on MNIST. We perform some basic preprocessing, and set up the data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "a6jMrCRa1y-d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 13223136.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 11302821.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0))])\n",
    "dataset = MNIST(\"./data\", train=True, download=True, transform=tf)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4, drop_last=True) # 1000/128 = 7 batches (drop last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our model with a given choice of hidden layers and activation function. We also choose a learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-6ApENps1y-d"
   },
   "outputs": [],
   "source": [
    "gt = CNN(in_channels=1, expected_shape=(28, 28), n_hidden=(16, 32, 32, 16), act=nn.GELU)\n",
    "# For testing: (16, 32, 32, 16)\n",
    "# For more capacity (for example): (64, 128, 256, 128, 64)\n",
    "ddpm = DDPM(gt=gt, betas=(1e-4, 0.02), n_T=1000)\n",
    "optim = torch.optim.Adam(ddpm.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could set up a GPU if we have one, which is done below.\n",
    "\n",
    "Here, we use HuggingFace's `accelerate` library, which abstracts away all the `.to(device)` calls for us.\n",
    "This lets us focus on the model itself rather than data movement.\n",
    "It also does a few other tricks to speed up calculations.\n",
    "\n",
    "PyTorch Lightning, which we discussed during the course, is another option that also handles a lot more, but is a bit heavyweight.\n",
    "`accelerate` is a simpler option closer to raw PyTorch.\n",
    "However, if you prefer, you could choose to use Lightning for the coursework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "# We wrap our model, optimizer, and dataloaders with `accelerator.prepare`,\n",
    "# which lets HuggingFace's Accelerate handle the device placement and gradient accumulation.\n",
    "ddpm, optim, dataloader = accelerator.prepare(ddpm, optim, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's just make sure this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8wxKbzEa1y-e"
   },
   "outputs": [],
   "source": [
    "for x, _ in dataloader:\n",
    "    break\n",
    "\n",
    "with torch.no_grad():\n",
    "    ddpm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train it. You can exit early by interrupting the kernel. Images\n",
    "are saved to the `contents` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLiE8x-c1y-e",
    "outputId": "a9f81c32-96c2-4e3b-cee9-fd2d2d4e316c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.139: 100%|██████████| 468/468 [00:30<00:00, 15.28it/s]\n",
      "loss: 0.0951: 100%|██████████| 468/468 [00:28<00:00, 16.48it/s]\n",
      "loss: 0.0774: 100%|██████████| 468/468 [00:22<00:00, 21.02it/s]\n",
      "loss: 0.0674: 100%|██████████| 468/468 [00:21<00:00, 21.41it/s]\n",
      "loss: 0.0606: 100%|██████████| 468/468 [00:23<00:00, 20.16it/s]\n",
      "loss: 0.0556: 100%|██████████| 468/468 [00:25<00:00, 18.08it/s]\n",
      "loss: 0.0518: 100%|██████████| 468/468 [00:22<00:00, 20.91it/s]\n",
      "loss: 0.0488: 100%|██████████| 468/468 [00:38<00:00, 12.25it/s]\n",
      "loss: 0.0463: 100%|██████████| 468/468 [00:27<00:00, 17.22it/s]\n",
      "loss: 0.0443: 100%|██████████| 468/468 [00:29<00:00, 16.00it/s]\n",
      "loss: 0.0426: 100%|██████████| 468/468 [00:33<00:00, 14.10it/s]\n",
      "loss: 0.0411: 100%|██████████| 468/468 [00:20<00:00, 22.29it/s]\n",
      "loss: 0.0398: 100%|██████████| 468/468 [00:21<00:00, 21.62it/s]\n",
      "loss: 0.0386: 100%|██████████| 468/468 [00:29<00:00, 15.93it/s]\n",
      "loss: 0.0376: 100%|██████████| 468/468 [00:25<00:00, 18.46it/s]\n",
      "loss: 0.0366: 100%|██████████| 468/468 [00:23<00:00, 20.16it/s]\n",
      "loss: 0.0358: 100%|██████████| 468/468 [00:22<00:00, 20.93it/s]\n",
      "loss: 0.0351: 100%|██████████| 468/468 [00:27<00:00, 16.89it/s]\n",
      "loss: 0.0344: 100%|██████████| 468/468 [00:27<00:00, 16.95it/s]\n",
      "loss: 0.0337: 100%|██████████| 468/468 [00:28<00:00, 16.37it/s]\n",
      "loss: 0.0331: 100%|██████████| 468/468 [00:29<00:00, 15.85it/s]\n",
      "loss: 0.0326: 100%|██████████| 468/468 [00:27<00:00, 17.21it/s]\n",
      "loss: 0.0321: 100%|██████████| 468/468 [00:23<00:00, 19.93it/s]\n",
      "loss: 0.0316: 100%|██████████| 468/468 [00:28<00:00, 16.52it/s]\n",
      "loss: 0.0312: 100%|██████████| 468/468 [00:30<00:00, 15.47it/s]\n",
      "loss: 0.0308: 100%|██████████| 468/468 [00:27<00:00, 17.16it/s]\n",
      "loss: 0.0304: 100%|██████████| 468/468 [00:24<00:00, 19.31it/s]\n",
      "loss: 0.03: 100%|██████████| 468/468 [00:22<00:00, 20.94it/s]  \n",
      "loss: 0.0297: 100%|██████████| 468/468 [00:27<00:00, 17.11it/s]\n",
      "loss: 0.0294: 100%|██████████| 468/468 [00:34<00:00, 13.42it/s]\n",
      "loss: 0.0291: 100%|██████████| 468/468 [00:38<00:00, 12.19it/s]\n",
      "loss: 0.0288: 100%|██████████| 468/468 [00:30<00:00, 15.14it/s]\n",
      "loss: 0.0285: 100%|██████████| 468/468 [00:28<00:00, 16.57it/s]\n",
      "loss: 0.0282: 100%|██████████| 468/468 [00:29<00:00, 15.70it/s]\n",
      "loss: 0.028: 100%|██████████| 468/468 [00:26<00:00, 17.96it/s] \n",
      "loss: 0.0277: 100%|██████████| 468/468 [00:30<00:00, 15.13it/s]\n",
      "loss: 0.0275: 100%|██████████| 468/468 [00:30<00:00, 15.38it/s]\n",
      "loss: 0.0273: 100%|██████████| 468/468 [00:28<00:00, 16.32it/s]\n",
      "loss: 0.0271: 100%|██████████| 468/468 [00:31<00:00, 14.79it/s]\n",
      "loss: 0.0269: 100%|██████████| 468/468 [00:21<00:00, 21.67it/s]\n",
      "loss: 0.0267: 100%|██████████| 468/468 [00:31<00:00, 14.77it/s]\n",
      "loss: 0.0265: 100%|██████████| 468/468 [00:33<00:00, 14.10it/s]\n",
      "loss: 0.0263: 100%|██████████| 468/468 [00:29<00:00, 15.86it/s]\n",
      "loss: 0.0261: 100%|██████████| 468/468 [00:26<00:00, 18.00it/s]\n",
      "loss: 0.026: 100%|██████████| 468/468 [00:23<00:00, 19.78it/s] \n",
      "loss: 0.0258: 100%|██████████| 468/468 [00:25<00:00, 18.53it/s]\n",
      "loss: 0.0257: 100%|██████████| 468/468 [00:38<00:00, 12.30it/s]\n",
      "loss: 0.0255: 100%|██████████| 468/468 [00:28<00:00, 16.32it/s]\n",
      "loss: 0.0254: 100%|██████████| 468/468 [00:23<00:00, 19.87it/s]\n",
      "loss: 0.0252: 100%|██████████| 468/468 [00:28<00:00, 16.19it/s]\n",
      "loss: 0.0251: 100%|██████████| 468/468 [00:27<00:00, 17.30it/s]\n",
      "loss: 0.025: 100%|██████████| 468/468 [00:21<00:00, 21.85it/s] \n",
      "loss: 0.0249: 100%|██████████| 468/468 [00:22<00:00, 20.88it/s]\n",
      "loss: 0.0247: 100%|██████████| 468/468 [00:25<00:00, 18.51it/s]\n",
      "loss: 0.0246: 100%|██████████| 468/468 [00:34<00:00, 13.59it/s]\n",
      "loss: 0.0245: 100%|██████████| 468/468 [00:28<00:00, 16.52it/s]\n",
      "loss: 0.0244: 100%|██████████| 468/468 [00:27<00:00, 17.27it/s]\n",
      "loss: 0.0243: 100%|██████████| 468/468 [00:24<00:00, 18.82it/s]\n",
      "loss: 0.0242: 100%|██████████| 468/468 [00:27<00:00, 17.11it/s]\n",
      "loss: 0.0241: 100%|██████████| 468/468 [00:25<00:00, 18.71it/s]\n",
      "loss: 0.024: 100%|██████████| 468/468 [00:24<00:00, 19.37it/s] \n",
      "loss: 0.0239: 100%|██████████| 468/468 [00:24<00:00, 18.76it/s]\n",
      "loss: 0.0238: 100%|██████████| 468/468 [00:28<00:00, 16.33it/s]\n",
      "loss: 0.0237: 100%|██████████| 468/468 [00:21<00:00, 21.80it/s]\n",
      "loss: 0.0236: 100%|██████████| 468/468 [00:26<00:00, 17.43it/s]\n",
      "loss: 0.0235: 100%|██████████| 468/468 [00:30<00:00, 15.36it/s]\n",
      "loss: 0.0234: 100%|██████████| 468/468 [00:25<00:00, 18.55it/s]\n",
      "loss: 0.0234: 100%|██████████| 468/468 [00:32<00:00, 14.46it/s]\n",
      "loss: 0.0233: 100%|██████████| 468/468 [00:32<00:00, 14.52it/s]\n",
      "loss: 0.0232: 100%|██████████| 468/468 [00:32<00:00, 14.48it/s]\n",
      "loss: 0.0231: 100%|██████████| 468/468 [00:26<00:00, 18.00it/s]\n",
      "loss: 0.023: 100%|██████████| 468/468 [00:32<00:00, 14.47it/s] \n",
      "loss: 0.023: 100%|██████████| 468/468 [00:29<00:00, 15.69it/s]\n",
      "loss: 0.0229: 100%|██████████| 468/468 [00:21<00:00, 21.55it/s]\n",
      "loss: 0.0228: 100%|██████████| 468/468 [00:27<00:00, 16.92it/s]\n",
      "loss: 0.0228: 100%|██████████| 468/468 [00:34<00:00, 13.75it/s]\n",
      "loss: 0.0227: 100%|██████████| 468/468 [00:32<00:00, 14.33it/s]\n",
      "loss: 0.0226: 100%|██████████| 468/468 [00:32<00:00, 14.42it/s]\n",
      "loss: 0.0226: 100%|██████████| 468/468 [00:25<00:00, 18.64it/s]\n",
      "loss: 0.0225: 100%|██████████| 468/468 [00:23<00:00, 20.10it/s]\n",
      "loss: 0.0224: 100%|██████████| 468/468 [00:32<00:00, 14.22it/s]\n",
      "loss: 0.0224: 100%|██████████| 468/468 [00:23<00:00, 19.82it/s]\n",
      "loss: 0.0223: 100%|██████████| 468/468 [00:23<00:00, 20.20it/s]\n",
      "loss: 0.0223: 100%|██████████| 468/468 [00:31<00:00, 14.68it/s]\n",
      "loss: 0.0222: 100%|██████████| 468/468 [00:25<00:00, 18.07it/s]\n",
      "loss: 0.0222: 100%|██████████| 468/468 [00:34<00:00, 13.75it/s]\n",
      "loss: 0.0221: 100%|██████████| 468/468 [00:31<00:00, 14.82it/s]\n",
      "loss: 0.022: 100%|██████████| 468/468 [00:26<00:00, 17.93it/s] \n",
      "loss: 0.022: 100%|██████████| 468/468 [00:32<00:00, 14.42it/s]\n",
      "loss: 0.0219: 100%|██████████| 468/468 [00:21<00:00, 21.57it/s]\n",
      "loss: 0.0219: 100%|██████████| 468/468 [00:27<00:00, 16.99it/s]\n",
      "loss: 0.0218: 100%|██████████| 468/468 [00:28<00:00, 16.62it/s]\n",
      "loss: 0.0218: 100%|██████████| 468/468 [00:29<00:00, 16.00it/s]\n",
      "loss: 0.0217: 100%|██████████| 468/468 [00:33<00:00, 14.15it/s]\n",
      "loss: 0.0217: 100%|██████████| 468/468 [00:27<00:00, 16.88it/s]\n",
      "loss: 0.0217: 100%|██████████| 468/468 [00:31<00:00, 15.02it/s]\n",
      "loss: 0.0216: 100%|██████████| 468/468 [00:22<00:00, 20.41it/s]\n",
      "loss: 0.0216: 100%|██████████| 468/468 [00:28<00:00, 16.24it/s]\n",
      "loss: 0.0215: 100%|██████████| 468/468 [00:31<00:00, 14.84it/s]\n",
      "loss: 0.0215: 100%|██████████| 468/468 [00:22<00:00, 21.21it/s]\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "losses = []\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    ddpm.train()\n",
    "\n",
    "    pbar = tqdm(dataloader)  # Wrap our loop with a visual progress bar\n",
    "    for x, _ in pbar:\n",
    "        optim.zero_grad()\n",
    "\n",
    "        loss = ddpm(x)\n",
    "\n",
    "        loss.backward()\n",
    "        # ^Technically should be `accelerator.backward(loss)` but not necessary for local training\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        avg_loss = np.average(losses[min(len(losses)-100, 0):])\n",
    "        pbar.set_description(f\"epoch {i+1}/{n_epoch}, loss: {avg_loss:.3f}\")\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    ddpm.eval()\n",
    "    with torch.no_grad():\n",
    "        xh = ddpm.sample(16, (1, 28, 28), accelerator.device)  # Can get device explicitly with `accelerator.device`\n",
    "        grid = make_grid(xh, nrow=4)\n",
    "\n",
    "        # Save samples to `./contents` directory\n",
    "        save_image(grid, f\"./contents/ddpm_sample_{i:04d}.png\")\n",
    "\n",
    "        # save model\n",
    "        torch.save(ddpm.state_dict(), f\"./ddpm_mnist.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\appfiles\\anaconda\\envs\\cw_aml\\Lib\\site-packages\\numpy\\lib\\function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "d:\\appfiles\\anaconda\\envs\\cw_aml\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize average loss per epoch\n",
    "import matplotlib.pyplot as plt\n",
    "len(losses)# 7*128*100\n",
    "loss_per_epoch = [np.average(losses[i*7*128:(i+1)*7*128]) for i in range(100)]\n",
    "plt.plot(loss_per_epoch)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
